{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":false},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"code","source":"# 폴더 압축 풀기\nimport zipfile\n\nwith zipfile.ZipFile('../input/tgs-salt-identification-challenge/train.zip', 'r') as z:\n    z.extractall('train')\n    \nwith zipfile.ZipFile('../input/tgs-salt-identification-challenge/test.zip', 'r') as z:\n    z.extractall('test')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train_id = os.listdir('train/images')\ntest_id = os.listdir('test/images')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train = pd.read_csv(\"../input/tgs-salt-identification-challenge/train.csv\")\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from keras.preprocessing.image import load_img\n\ntrain['images'] = [np.array(load_img(\"train/images/\" + i, grayscale=True)) / 255 for i in train_id]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train[\"id\"] = train_id\ntrain[\"id\"] = train[\"id\"].apply(lambda x: x.split(\".\")[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train[\"mask\"] = [np.array(load_img(\"train/masks/\" + i, grayscale=True)) / 255 for i in train_id] # 0,1로 바꿔주려고 255로 나눔","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train[\"coverage\"] = train[\"mask\"].apply(np.sum) / 10201","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train[\"coverage_class\"] =  np.ceil(train[\"coverage\"] * 10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train[\"coverage_class\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_valid, y_train, y_valid = train_test_split(np.array(train[\"images\"].tolist()).reshape(-1, 101, 101, 1), \n                                                      np.array(train[\"mask\"].tolist()).reshape(-1, 101, 101, 1), stratify=train[\"coverage_class\"],\n                                                      test_size=0.2, random_state=777)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from imgaug import augmenters as iaa\nimport imgaug as resize_iaa\n\ndef augmentation(aug1, aug2, X_train, y_train):\n    aug_det = aug1.to_deterministic() # augmentation이 랜덤하게 되면 안된다.(random_state 고정하는 것과 같은 효과)\n    X_train_aug = aug_det.augment_image(X_train)\n    X_train_aug = aug2.augment_image(X_train_aug)\n    y_train_aug = aug_det.augment_image(y_train)\n    \n    if y_train_aug.shape != (101, 101): # crop 하면 이미지 사이즈가 변한다.\n        X_train_aug = resize_iaa.imresize_single_image(X_train_aug, (101, 101), interpolation=\"linear\")\n        y_train_aug = resize_iaa.imresize_single_image(y_train_aug, (101, 101), interpolation=\"nearest\")\n    \n    return np.array(X_train_aug), np.array(y_train_aug)\n\nsometimes = lambda x: iaa.Sometimes(0.5, x)\n# aug1 : mask도 같이 augmentaion, aug2 : aug2만 적용\naug1 = iaa.Sequential([\n    iaa.Fliplr(0.5), \n    iaa.OneOf([\n        iaa.Affine(rotate=(-10, 10),translate_percent={\"x\": (-0.25, 0.25)}, mode='symmetric', cval=(0), backend=\"cv2\"), #Affine transform : linear transform (선형 결합을 통한 차원변환)\n        iaa.CropAndPad(percent=(-0.2, 0.2), pad_mode=\"reflect\", pad_cval=0, keep_size=False), # 확대해서 crop\n        iaa.Noop(), iaa.Noop()\n    ])\n]) # OneOf : augmentation 중에서 어떤걸 할지(같이 실행하지 않기위해), Noop : 아무것도 안하는것(3번중 1번 실행)\n\naug2 = iaa.Sequential(\n    sometimes(iaa.Multiply((0.8, 1.2))),\n    sometimes(iaa.Add((-0.2, 0.2))),\n    sometimes(iaa.OneOf([iaa.AdditiveGaussianNoise(scale=(0, 0.05)), iaa.GaussianBlur(sigma=(0.0, 1.0))]))\n)\n\ndef generator(image, mask, batch_size=32):\n    idx = np.arange(len(image))\n    images, masks = [], []\n    \n    while True:\n        np.random.shuffle(idx)\n        for i in idx:\n            aug_img, aug_mask = augmentation(aug1, aug2, image[i], mask[i])\n            images += [aug_img]\n            masks += [aug_mask]\n            \n            if len(images) >= batch_size:\n                yield np.stack(images, 0), np.stack(masks, 0)\n                images, masks = [], []\n                ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# x, y = next(generator(X_train, y_train))\n# plt.figure(figsize=(20, 12))\n# plt.imshow(x[0].reshape(101, 101))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# degradiation 문제(gradient vanishing 문제) : train/valid 점수가 둘다 안나오면 학습 자체가 전달이 안된다.\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from keras.models import Model\nfrom keras.layers import *\n\ndef conv_block(x, filters, size, strides=(1,1), padding=\"same\", activation=True):\n    x = Conv2D(filters, size, strides=strides, padding=padding)(x)\n    x = BatchNormalization()(x)\n    if activation:\n        x = Activation(\"relu\")(x)\n    return x\n\ndef res_block(block_input, num_filters=16):\n    x = Activation(\"relu\")(block_input)\n    x = BatchNormalization()(x)\n    x = conv_block(x, num_filters, (3,3)) # 함수는 층이 아니라서 연결시키지 않음 (return x)\n    x = conv_block(x, num_filters, (3,3), activation=False)\n    x = Add()([x, block_input])\n    return x\n\ndef build_model(input_layer, neuron, dropout=0.5):\n    cnn1 = Conv2D(neuron*1, (3,3), activation=None, padding=\"same\")(input_layer)\n    cnn1 = res_block(cnn1, neuron*1)\n    cnn1 = res_block(cnn1, neuron*1)\n    cnn1 = Activation(\"relu\")(cnn1)\n    poo1 = MaxPooling2D(2,2)(cnn1)\n    poo1 = Dropout(dropout/2)(poo1)\n    \n    cnn2 = Conv2D(neuron*2, (3,3), activation=None, padding=\"same\")(poo1)\n    cnn2 = res_block(cnn2, neuron*2)\n    cnn2 = res_block(cnn2, neuron*2)\n    cnn2 = Activation(\"relu\")(cnn2)\n    poo2 = MaxPooling2D(2,2)(cnn2)\n    poo2 = Dropout(dropout)(poo2)\n    \n    cnn3 = Conv2D(neuron*4, (3,3), activation=None, padding=\"same\")(poo2)\n    cnn3 = res_block(cnn3, neuron*4)\n    cnn3 = res_block(cnn3, neuron*4)\n    cnn3 = Activation(\"relu\")(cnn3)\n    poo3 = MaxPooling2D(2,2)(cnn3)\n    poo3 = Dropout(dropout)(poo3)\n    \n    cnn4 = Conv2D(neuron*8, (3,3), activation=None, padding=\"same\")(poo3)\n    cnn4 = res_block(cnn4, neuron*8)\n    cnn4 = res_block(cnn4, neuron*8)\n    cnn4 = Activation(\"relu\")(cnn4)\n    poo4 = MaxPooling2D(2,2)(cnn4)\n    poo4 = Dropout(dropout)(poo4)\n    \n    cnn_mid = Conv2D(neuron*16, (3,3), activation=None, padding=\"same\")(poo4) # size=6\n    cnn_mid = res_block(cnn_mid, neuron*16)\n    cnn_mid = res_block(cnn_mid, neuron*16)\n    cnn_mid = Activation(\"relu\")(cnn_mid)\n    \n    dcnn4 = Conv2DTranspose(neuron*8, (3,3), strides=(2,2), padding=\"same\")(cnn_mid) # size=12\n    cnn4 = concatenate([dcnn4, cnn4])\n    cnn4 = Dropout(dropout)(cnn4)\n    cnn4 = Conv2D(neuron*8, (3,3), activation=None, padding=\"same\")(cnn4)\n    cnn4 = res_block(cnn4, neuron*8)\n    cnn4 = res_block(cnn4, neuron*8)\n    cnn4 = Activation(\"relu\")(cnn4)\n    \n    dcnn3 = Conv2DTranspose(neuron*4, (3,3), strides=(2,2), padding=\"valid\")(cnn4) # size=(24 -->) 25\n    cnn3 = concatenate([dcnn3, cnn3])\n    cnn3 = Dropout(dropout)(cnn3)\n    cnn3 = Conv2D(neuron*4, (3,3), activation=None, padding=\"same\")(cnn3)\n    cnn3 = res_block(cnn3, neuron*4)\n    cnn3 = res_block(cnn3, neuron*4)\n    cnn3 = Activation(\"relu\")(cnn3)\n    \n    dcnn2 = Conv2DTranspose(neuron*2, (3,3), strides=(2,2), padding=\"same\")(cnn3) # size=50\n    cnn2 = concatenate([dcnn2, cnn2])\n    cnn2 = Dropout(dropout)(cnn2)\n    cnn2 = Conv2D(neuron*2, (3,3), activation=None, padding=\"same\")(cnn2)\n    cnn2 = res_block(cnn2, neuron*2)\n    cnn2 = res_block(cnn2, neuron*2)\n    cnn2 = Activation(\"relu\")(cnn2)\n    \n    dcnn1 = Conv2DTranspose(neuron*1, (3,3), strides=(2,2), padding=\"valid\")(cnn2) # size=(100 -->) 101\n    cnn1 = concatenate([dcnn1, cnn1])\n    cnn1 = Dropout(dropout)(cnn1)\n    cnn1 = Conv2D(neuron*1, (3,3), activation=None, padding=\"same\")(cnn1)\n    cnn1 = res_block(cnn1, neuron*1)\n    cnn1 = res_block(cnn1, neuron*1)\n    cnn1 = Activation(\"relu\")(cnn1)\n    \n    cnn1 = Dropout(dropout/2)(cnn1)\n    output_layer = Conv2D(1, (1,1), activation=\"sigmoid\")(cnn1)\n    \n    return output_layer","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"input_layer = Input((101, 101, 1))\nouput_layer = build_model(input_layer, 16, 0.5)\nmodel = Model(input_layer, ouput_layer)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train_generator = generator(X_train, y_train, 128)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false},"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nmodel.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"acc\"])\n\ncallbacks = [ModelCheckpoint(\"best.h5\", save_best_only=True, verbose=1),\n             EarlyStopping(patience=20),\n             ReduceLROnPlateau(patience=8, factor=0.15, min_lr=0.00001, verbose=1)] # min_lr: 너무 낮아지는 것은 방지\n\nmodel.fit_generator(train_generator, validation_data=[X_valid, y_valid], epochs=100, callbacks=callbacks, steps_per_epoch=np.ceil(len(X_train)/128))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"model.load_weights(\"../input/best-weights/best.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"preds_valid = model.predict(X_valid).reshape(-1, 101, 101)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"threshold = np.linspace(0.3, 0.7, 31)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def iou_metric(y_true_in, y_pred_in, print_table=False):\n    labels = y_true_in\n    y_pred = y_pred_in\n    \n    true_objects = 2\n    pred_objects = 2\n\n    #  if all zeros, original code  generate wrong  bins [-0.5 0 0.5],\n    temp1 = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=([0,0.5,1], [0,0.5, 1]))\n    intersection = temp1[0]\n    area_true = np.histogram(labels,bins=[0,0.5,1])[0]\n    area_pred = np.histogram(y_pred, bins=[0,0.5,1])[0]\n    area_true = np.expand_dims(area_true, -1)\n    area_pred = np.expand_dims(area_pred, 0)\n\n    # Compute union\n    union = area_true + area_pred - intersection\n\n    # Exclude background from the analysis\n    intersection = intersection[1:,1:]\n    intersection[intersection == 0] = 1e-9\n    \n    union = union[1:,1:]\n    union[union == 0] = 1e-9\n\n    # Compute the intersection over union\n    iou = intersection / union\n    # Precision helper function\n    def precision_at(threshold, iou):\n        matches = iou > threshold\n        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n        return tp, fp, fn\n\n    # Loop over IoU thresholds\n    prec = []\n    if print_table:\n        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n    for t in np.arange(0.5, 1.0, 0.05):\n        tp, fp, fn = precision_at(t, iou)\n        if (tp + fp + fn) > 0:\n            p = tp / (tp + fp + fn)\n        else:\n            p = 0\n        if print_table:\n            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n        prec.append(p)\n        \n    if print_table:\n        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n    return np.mean(prec)\n\ndef iou_metric_batch(y_true_in, y_pred_in):\n    batch_size = y_true_in.shape[0]\n    metric = []\n    for batch in range(batch_size):\n        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n        metric.append(value)\n    return np.mean(metric)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"ious = np.array([iou_metric_batch(y_valid, preds_valid>i) for i in threshold])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"threshold_best_idx = np.argmax(ious)\niou_best = ious[threshold_best_idx]\nthreshold_best  = threshold[threshold_best_idx]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.plot(threshold, ious)\nplt.plot(threshold_best, iou_best, \"og\", label=\"best_threshold\")\nplt.legend()\nplt.title(\"threshold : {} vs. iou : {}\".format(threshold_best, iou_best))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def rle_encode(im):\n    pixels = im.flatten(order = 'F')\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from tqdm import tqdm_notebook\nx_test = np.array([(np.array(load_img(\"test/images/{}\".format(idx), grayscale = True))) / 255 for idx in tqdm_notebook(test_id)]).reshape(-1, 101, 101, 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"preds_test = model.predict(x_test, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"prediction_dict = {idx: rle_encode(preds_test[i]>threshold_best) for i, idx in enumerate(tqdm_notebook(test_id))}","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"sub = pd.DataFrame.from_dict(prediction_dict, orient=\"index\").reset_index()\nsub.columns = [\"id\", \"rle_mask\"]\nsub[\"id\"] = sub[\"id\"].apply(lambda x: x[:-4])\nsub.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"sub.to_csv(\"sub.csv\", index=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}